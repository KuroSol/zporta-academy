# AI Core System - Implementation Guide

## üéØ Overview

The **AI Core System** is a unified, cost-efficient AI infrastructure for Zporta Academy that:

1. ‚úÖ **Keeps ALL existing features intact** (user categories, LLM dropdowns, TTS providers, etc.)
2. ‚úÖ **Adds intelligent caching** to never pay twice for the same content
3. ‚úÖ **Centralizes all AI calls** through one router for easy monitoring
4. ‚úÖ **Tracks costs** per request, per provider, per user
5. ‚úÖ **Prepares training data** for our own fine-tuned model
6. ‚úÖ **Auto-selects cheapest good model** or allows manual choice

---

## üìÅ New Structure

```
ai_core/                          # NEW APP (coexists with dailycast)
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ apps.py
‚îú‚îÄ‚îÄ models.py                     # 5 new models (see below)
‚îú‚îÄ‚îÄ admin.py                      # Admin interfaces for all models
‚îú‚îÄ‚îÄ services.py                   # Central AI router (generate_text, generate_audio)
‚îî‚îÄ‚îÄ management/
    ‚îî‚îÄ‚îÄ commands/
        ‚îî‚îÄ‚îÄ setup_ai_providers.py # Populate initial provider configs
```

---

## üóÑÔ∏è New Models

### 1. **AiProviderConfig** (AI Provider Configuration)
**Purpose**: Central config for all AI models (text + audio)

**Fields**:
- `provider`: 'openai', 'gemini', 'claude', 'elevenlabs', 'google_tts', 'local_small_model'
- `model_name`: e.g. 'gpt-4o-mini', 'gemini-2.0-pro-exp'
- `tier`: 'cheap', 'normal', 'premium'
- `cost_per_million_tokens`: USD cost per 1M tokens
- `cost_per_request`: USD cost per request (for TTS/images)
- `quality_score`: 0.0-1.0 rating
- `is_active`: Enable/disable this provider
- `is_default`: Use as default for this tier
- `max_tokens`: Max context size
- `capabilities`: JSON with supported features

**Usage**: Admin can add/edit providers, adjust costs, enable/disable models.

---

### 2. **AiMemory** (Smart Cache for AI Content)
**Purpose**: Cache ALL AI-generated content to avoid duplicate API calls

**Key Features**:
- **Deduplication**: Uses `prompt_hash` (SHA256 of normalized prompt + options)
- **Quality tracking**: `is_verified_good`, `user_rating`, `usage_count`
- **Training data**: Flag good examples with `use_for_training`
- **Audio storage**: Saves TTS audio files with metadata
- **Reusability**: If exact same request comes again ‚Üí return cached response (0 cost!)

**Fields**:
- `request_type`: 'podcast_script', 'quiz_generation', 'lesson_script', 'tts_audio', etc.
- `prompt_hash`: Unique hash for deduplication
- `prompt_text`: Original prompt
- `prompt_options`: JSON with language, difficulty, etc.
- `generated_text`: AI response text
- `generated_audio_file`: TTS MP3 file (if applicable)
- `provider`, `model`: Which AI was used
- `tokens_used`, `cost_estimate`, `latency_ms`: Performance metrics
- `is_verified_good`: Admin-approved high quality (use for training)
- `user_rating`: Average user rating (0-5)
- `usage_count`: How many times this cached result was reused

---

### 3. **AiTrainingData** (Curated Dataset for Fine-Tuning)
**Purpose**: Track verified, high-quality examples for training our own model

**Fields**:
- `memory_item`: Link to AiMemory item
- `training_weight`: Importance (1.0 = normal, 2.0 = double weight)
- `difficulty_label`: 'easy', 'medium', 'hard'
- `subject_tags`: ['jlpt_n5', 'grammar', 'math', etc.]
- `human_verified`: Admin manually approved
- `verified_by`, `verified_at`: Who and when
- `included_in_training`: Already used in a training run
- `training_batch_id`: Which batch included this example

**Usage**: Admin reviews AI-generated content, marks best examples for training.

---

### 4. **AiUsageLog** (Cost & Performance Tracking)
**Purpose**: Log EVERY AI request for cost monitoring and analytics

**Fields**:
- `request_type`: What was requested
- `endpoint`: Which function made the call
- `user`: Who requested it (optional)
- `provider`, `model`: Which AI was used
- `tokens_used`, `cost_estimate`, `latency_ms`: Performance
- `cache_hit`: True if served from AiMemory cache (0 cost!)
- `selection_mode`: 'auto' or 'manual'
- `success`: True/False
- `error_message`: If failed

**Usage**: Admin dashboard shows:
- Total cost last 30 days
- Cache hit rate (how much money saved)
- Top expensive endpoints
- Per-provider breakdown

---

### 5. **AiModelTrainingRun** (Training History)
**Purpose**: Track each fine-tuning run for our own model

**Fields**:
- `training_batch_id`: Unique ID (e.g. 'zporta_2025_01')
- `model_version`: 'zporta_v1', 'zporta_v2', etc.
- `training_size`: Number of examples used
- `base_model`: e.g. 'gpt-4o-mini', 'gemini-flash'
- `training_provider`: 'openai', 'google', etc.
- `training_cost`: USD spent on training
- `training_duration_minutes`: How long it took
- `validation_accuracy`, `validation_loss`: Performance metrics
- `status`: 'pending', 'training', 'completed', 'failed', 'deployed'
- `is_active`: Currently in production use

**Usage**: Track training experiments, costs, and which version is deployed.

---

## üîß Central AI Router

### **Function: `generate_text()`**

**Location**: `ai_core/services.py`

**Purpose**: ONE entry point for ALL text generation across entire platform

**Usage Example**:
```python
from ai_core.services import generate_text

# Auto mode (system picks cheapest good model)
script, provider = generate_text(
    request_type='podcast_script',
    prompt="Create a podcast about JLPT N5 grammar...",
    options={'language': 'ja', 'difficulty': 'easy'},
    selection_mode='auto',
    user=request.user,
    endpoint='dailycast.services.create_podcast'
)

# Manual mode (user/admin specifies exact model)
script, provider = generate_text(
    request_type='lesson_script',
    prompt="Explain quantum physics...",
    provider='openai',
    model='gpt-4o',
    selection_mode='manual',
    user=request.user
)
```

**What it does**:
1. **Check cache first**: Compute `prompt_hash`, look in AiMemory
2. **Cache hit?** ‚Üí Return cached text immediately (0 cost!)
3. **Cache miss?** ‚Üí Select AI model (auto or manual)
4. **Call AI provider**: OpenAI, Gemini, Claude, or local model
5. **Save to cache**: Store in AiMemory for future reuse
6. **Log usage**: Track cost, latency, tokens in AiUsageLog

**Returns**: `(generated_text, provider_name)`

---

### **Function: `generate_audio()`**

**Location**: `ai_core/services.py`

**Purpose**: ONE entry point for ALL TTS/audio generation

**Usage Example**:
```python
from ai_core.services import generate_audio

# Auto mode (picks best TTS for language)
audio_bytes, provider = generate_audio(
    text="Welcome to JLPT lesson 5...",
    language='ja',
    selection_mode='auto',
    user=request.user
)

# Manual mode (specific provider)
audio_bytes, provider = generate_audio(
    text="Hello world",
    language='en',
    provider='elevenlabs',
    voice_id='Lily',
    selection_mode='manual'
)
```

**What it does**:
1. **Check audio cache**: Compute `text_hash` + language + voice_id
2. **Cache hit?** ‚Üí Return MP3 file immediately (0 cost!)
3. **Cache miss?** ‚Üí Select TTS provider (ElevenLabs, OpenAI, Google)
4. **Generate audio**: Call TTS API
5. **Save MP3 to cache**: Store in AiMemory with audio file
6. **Log usage**: Track cost and latency

**Returns**: `(audio_bytes, provider_name)`

---

## üß† Auto-Selection Logic

### Text Models (generate_text)

```python
def _auto_select_model(request_type, options):
    # Determine tier
    tier = 'cheap'  # Default
    
    # Important content ‚Üí Normal tier
    if request_type in ['podcast_script', 'report', 'lesson_script']:
        tier = 'normal'
    
    # Explicit premium request ‚Üí Premium tier
    if options.get('quality') == 'premium' or options.get('deep_reasoning'):
        tier = 'premium'
    
    # Get cheapest model in this tier
    config = AiProviderConfig.objects.filter(
        tier=tier,
        is_active=True
    ).order_by('cost_per_million_tokens', '-quality_score').first()
    
    return config.provider, config.model_name
```

**Tiers**:
- **Cheap** (`gpt-4o-mini`, `gemini-1.5-flash`): Simple quizzes, drills, basic reports
- **Normal** (`gpt-4o`, `gemini-1.5-pro`): Podcasts, lesson scripts, important content
- **Premium** (`gpt-4-turbo`, `claude-3-5-sonnet`): Complex reasoning, long context

---

### TTS Models (generate_audio)

```python
def _auto_select_tts_provider(language):
    # Prefer ElevenLabs for quality (if API key exists)
    if has_elevenlabs_key():
        return 'elevenlabs'
    
    # Fallback to OpenAI TTS
    return 'openai'
```

---

## üéì Training Our Own Model (Future Phase)

### Step 1: Collect Data
- Admin reviews AI-generated content in **AiMemory** admin
- Marks best examples with **"‚úì Mark as Verified (Training)"** action
- System automatically tags them for training

### Step 2: Export Training Data
```python
from ai_core.services import export_training_data

# Export all verified, high-quality examples
dataset = export_training_data(
    min_rating=4.0,
    verified_only=True
)

# Format: [{"prompt": "...", "completion": "...", "tags": [...]}]
```

### Step 3: Fine-Tune Model
```bash
# Example using OpenAI (or Gemini, or local)
python manage.py train_zporta_model \
    --base-model gpt-4o-mini \
    --data-file training_data.jsonl \
    --batch-id zporta_2025_01 \
    --model-version zporta_v1
```

### Step 4: Deploy Fine-Tuned Model
- Add to **AiProviderConfig**: `provider='local_small_model'`, `model='zporta_v1'`
- Set `tier='cheap'`, `is_default=True`
- System will auto-use it for cheap tier requests
- If quality drops ‚Üí Falls back to external models

---

## üí∞ Cost Control Tactics

### 1. Caching (Biggest Savings!)
- Before ANY external API call ‚Üí Check AiMemory
- Same prompt + options ‚Üí Reuse cached response
- **Savings**: 90%+ for routine content

### 2. Deduplication
- Normalize prompts before hashing (strip whitespace, lowercase, sort options)
- Combine multiple small requests into batches

### 3. Tier-Based Selection
- Don't use `gpt-4-turbo` for simple JLPT drills
- Use cheapest model that meets quality threshold

### 4. Context Control
- Send only minimal necessary context
- Use IDs and references instead of full lesson text

### 5. Monitoring
- **Admin Dashboard** shows:
  - Total cost last 30 days
  - Cache hit rate
  - Top expensive endpoints
  - Cost per provider

### 6. Local Model (Later)
- After collecting 5,000-10,000 verified examples ‚Üí Fine-tune
- Use `local_small_model` for Zporta-typical requests (0 cost!)
- Fallback to external if quality drops

---

## üìä Admin Dashboard

### Where: Django Admin ‚Üí AI Core ‚Üí AI Usage Logs

**Stats Shown**:
- **Last 30 Days**:
  - Total requests: 12,543
  - Total cost: $45.23
  - Cache hit rate: 87% (saved ~$300!)
  - Avg latency: 850ms
- **Last 7 Days**:
  - Total requests: 3,241
  - Total cost: $12.10
  - Cache hit rate: 92%
- **Top Expensive Providers**:
  1. openai/gpt-4o: $25.50 (5,234 requests)
  2. gemini/gemini-2.0-pro: $12.30 (7,109 requests)
  3. elevenlabs/multilingual_v2: $7.43 (2,100 requests)
- **Training Data Ready**: 1,234 verified examples

---

## üîó Integration with Existing Code

### Before (Old Way):
```python
# In dailycast/services_interactive.py
from dailycast.services_interactive import generate_podcast_script_with_courses

script, provider = generate_podcast_script_with_courses(
    user=user,
    primary_language='ja',
    secondary_language='en',
    user_stats=stats,
    output_format='both'
)
```

### After (New Way):
```python
# Use central AI router
from ai_core.services import generate_text

# Build prompt from user stats
prompt = build_prompt_from_user_stats(user, stats, language)

# Call central router (auto caching + cost tracking!)
script, provider = generate_text(
    request_type='podcast_script',
    prompt=prompt,
    options={
        'language': 'ja',
        'secondary_language': 'en',
        'output_format': 'both',
        'user_id': user.id
    },
    selection_mode='auto',  # or 'manual' if user picked specific model
    user=user,
    endpoint='dailycast.services.create_podcast'
)
```

**Benefits**:
- ‚úÖ Automatic caching (reuse if same prompt seen before)
- ‚úÖ Cost tracking (logged in AiUsageLog)
- ‚úÖ Auto model selection (picks cheapest good model)
- ‚úÖ Training data collection (can mark as verified later)

---

## üìù Setup Instructions

### Step 1: Add to INSTALLED_APPS
```python
# settings/base.py
INSTALLED_APPS = [
    # ... existing apps ...
    'dailycast',
    'ai_core',  # NEW!
]
```

### Step 2: Run Migrations
```bash
cd c:\Users\AlexSol\Documents\zporta_academy\zporta_academy_backend
.\env\Scripts\Activate.ps1

python manage.py makemigrations ai_core
python manage.py migrate ai_core
```

### Step 3: Populate Provider Configs
```bash
python manage.py setup_ai_providers
```

**Output**:
```
Setting up AI Provider Configurations...
  ‚úì Created: openai/gpt-4o-mini (cheap)
  ‚úì Created: openai/gpt-4o (normal)
  ‚úì Created: gemini/gemini-1.5-flash (cheap)
  ‚úì Created: gemini/gemini-1.5-pro (normal)
  ‚úì Created: claude/claude-3-haiku (cheap)
  ‚úì Created: elevenlabs/eleven_multilingual_v2 (normal)
  ‚úì Created: google_tts/neural2 (cheap)

‚úÖ Setup complete!
  Created: 11 configurations
```

### Step 4: Test in Admin
1. Go to: http://localhost:8000/admin/ai_core/
2. Check **AI Provider Configs** (should see 11 entries)
3. Check **AI Memory** (empty until first AI call)
4. Check **AI Usage Logs** (empty until first AI call)

### Step 5: Update Existing Code (Optional)
Replace direct AI calls with `generate_text()` or `generate_audio()`:

```python
# Example: Update podcast generation
from ai_core.services import generate_text

# OLD:
# script, provider = _call_openai_for_text(...)

# NEW:
script, provider = generate_text(
    request_type='podcast_script',
    prompt=prompt,
    options={'language': 'ja'},
    selection_mode='auto',
    user=user
)
```

---

## ‚úÖ Verification Checklist

After setup, verify:

- [ ] **Migrations applied**: `python manage.py showmigrations ai_core`
- [ ] **Admin accessible**: Can browse AI Core models in admin
- [ ] **Provider configs loaded**: See 11 entries in AiProviderConfig
- [ ] **First AI call works**: Generate text ‚Üí Check AiMemory has 1 entry
- [ ] **Caching works**: Make same request twice ‚Üí 2nd is instant (cache hit)
- [ ] **Cost tracking works**: Check AiUsageLog has 2 entries (1 API, 1 cache)
- [ ] **Existing features intact**: User categories, LLM dropdowns still work

---

## üöÄ Next Steps

### Phase 1 (Now): Foundation
- ‚úÖ Models created
- ‚úÖ Admin interfaces ready
- ‚úÖ Central router (`generate_text`, `generate_audio`)
- ‚úÖ Caching system
- ‚úÖ Cost tracking

### Phase 2 (1-2 Weeks): Integration
- [ ] Update podcast generation to use `generate_text()`
- [ ] Update quiz generation to use `generate_text()`
- [ ] Update email generation to use `generate_text()`
- [ ] Update TTS to use `generate_audio()`
- [ ] Monitor cache hit rate (target: 80%+)

### Phase 3 (1 Month): Data Collection
- [ ] Admin reviews generated content
- [ ] Mark 500+ examples as verified
- [ ] Tag by subject/difficulty
- [ ] Export training dataset

### Phase 4 (2-3 Months): Fine-Tuning
- [ ] Collect 5,000-10,000 verified examples
- [ ] Fine-tune `gpt-4o-mini` or `gemini-flash` on our data
- [ ] Deploy as `local_small_model/zporta_v1`
- [ ] A/B test quality vs external models
- [ ] Monitor cost savings

---

## üìà Expected Savings

### Conservative Estimates (After Full Rollout):

**Current Costs** (Without AI Core):
- 10,000 AI requests/month
- No caching ‚Üí Every request hits API
- Cost: ~$200/month

**With AI Core** (After 1 Month):
- 10,000 AI requests/month
- 80% cache hit rate ‚Üí Only 2,000 API calls
- Auto-selects cheapest good models
- Cost: ~$50/month
- **Savings: $150/month (75%)**

**With Fine-Tuned Model** (After 3 Months):
- 10,000 AI requests/month
- 80% cache hit rate
- Of remaining 2,000:
  - 1,500 use `local_small_model` (near-zero cost)
  - 500 use external for complex tasks
- Cost: ~$15/month
- **Savings: $185/month (93%)**

---

## üîí Data Privacy & Security

- **User data**: Never stored in prompts (use IDs/references)
- **PII**: Stripped before caching
- **Audio files**: Stored in Django media folder (configurable)
- **API keys**: Stored in environment variables (not in database)
- **Training data**: Only verified, de-identified examples

---

## üìû Support & Questions

For questions about this system:
1. Check this guide first
2. Review admin interfaces
3. Check logs: `tail -f logs/django_errors.log`
4. Test in Django shell:
   ```bash
   python manage.py shell
   from ai_core.services import generate_text
   result, provider = generate_text(
       request_type='test',
       prompt='Hello AI!',
       selection_mode='auto'
   )
   print(result, provider)
   ```

---

## üéâ Summary

**What you get**:
1. ‚úÖ ALL existing features work exactly as before
2. ‚úÖ Smart caching ‚Üí 80%+ cost savings
3. ‚úÖ Central AI router ‚Üí Easy monitoring
4. ‚úÖ Cost tracking ‚Üí Know exactly what's expensive
5. ‚úÖ Training data collection ‚Üí Build our own model
6. ‚úÖ Auto vs Manual selection ‚Üí Flexibility for power users
7. ‚úÖ Future-proof ‚Üí Easy to add new AI providers

**What changes for users**: NOTHING! They don't even know it's there.

**What changes for admins**: Powerful new tools to monitor costs and improve quality.

**What changes for developers**: ONE clean API (`generate_text`, `generate_audio`) for all AI.

üöÄ **This is the AI infrastructure Zporta Academy needs to scale efficiently!**
