# AI Core System Architecture - Visual Guide

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ZPORTA ACADEMY                            â”‚
â”‚                     (Existing Features)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ ALL EXISTING FEATURES INTACT
                              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                         â”‚                         â”‚
    â–¼                         â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User    â”‚            â”‚   LLM       â”‚         â”‚   Podcast    â”‚
â”‚Category â”‚            â”‚  Dropdown   â”‚         â”‚  Generation  â”‚
â”‚System   â”‚            â”‚  (AJAX)     â”‚         â”‚   Service    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                         â”‚                         â”‚
    â”‚                         â”‚                         â”‚
    â”‚                         â–¼                         â”‚
    â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
    â”‚                  â”‚  AI CORE    â”‚                 â”‚
    â”‚                  â”‚  (NEW!)     â”‚                 â”‚
    â”‚                  â”‚             â”‚                 â”‚
    â”‚                  â”‚  Services:  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                  â”‚  - generate_â”‚
    â”‚                  â”‚    text()   â”‚
    â”‚                  â”‚  - generate_â”‚
    â”‚                  â”‚    audio()  â”‚
    â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                         â”‚
    â”‚                         â”‚
    â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      â”‚                  â”‚                  â”‚
    â”‚      â–¼                  â–¼                  â–¼
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  â”‚AiMemory  â”‚   â”‚AiProvider  â”‚   â”‚AiUsageLog  â”‚
    â”‚  â”‚(Cache)   â”‚   â”‚  Config    â”‚   â”‚(Tracking)  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚      â”‚                  â”‚                  â”‚
    â”‚      â”‚                  â”‚                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                  â”‚
           â”‚                  â–¼
           â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚          â”‚  AI Providersâ”‚
           â”‚          â”‚  - OpenAI    â”‚
           â”‚          â”‚  - Gemini    â”‚
           â”‚          â”‚  - Claude    â”‚
           â”‚          â”‚  - ElevenLabsâ”‚
           â”‚          â”‚  - Local Mdl â”‚
           â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                  â”‚
           â–¼                  â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      Training Data           â”‚
    â”‚   (Future Fine-Tuning)       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Request Flow (Text Generation)

### Scenario 1: First Request (Cache Miss)

```
1. User requests podcast
   â”‚
   â–¼
2. dailycast/services.py
   â”‚
   â”œâ”€â–º OLD PATH (Still works!)
   â”‚   â””â”€â–º Direct OpenAI call
   â”‚       â””â”€â–º Generate script
   â”‚           â””â”€â–º Return to user
   â”‚
   â””â”€â–º NEW PATH (Optional enhancement)
       â”‚
       â–¼
3. ai_core/services.py::generate_text()
   â”‚
   â”œâ”€â–º Check AiMemory (prompt_hash lookup)
   â”‚   â””â”€â–º NOT FOUND (cache miss)
   â”‚
   â”œâ”€â–º Select AI Model
   â”‚   â”œâ”€â–º Auto mode: Query AiProviderConfig
   â”‚   â”‚   â””â”€â–º Pick cheapest in 'normal' tier
   â”‚   â”‚       â””â”€â–º openai/gpt-4o-mini ($0.15/1M)
   â”‚   â”‚
   â”‚   â””â”€â–º Manual mode: Use user's choice
   â”‚       â””â”€â–º From UserCategoryConfig dropdown
   â”‚
   â”œâ”€â–º Call AI Provider
   â”‚   â””â”€â–º OpenAI API
   â”‚       â””â”€â–º Response: "Welcome to lesson 5..."
   â”‚       â””â”€â–º Cost: $0.05, Latency: 850ms
   â”‚
   â”œâ”€â–º Save to AiMemory
   â”‚   â””â”€â–º prompt_hash: abc123def456...
   â”‚   â””â”€â–º generated_text: "Welcome to..."
   â”‚   â””â”€â–º provider: openai, model: gpt-4o-mini
   â”‚   â””â”€â–º cost_estimate: 0.05, tokens: 1234
   â”‚
   â”œâ”€â–º Log to AiUsageLog
   â”‚   â””â”€â–º cache_hit: False
   â”‚   â””â”€â–º cost: $0.05
   â”‚   â””â”€â–º user: alex@example.com
   â”‚
   â””â”€â–º Return: ("Welcome to...", "openai")
```

### Scenario 2: Second Request (Cache Hit!)

```
1. User requests SAME podcast
   â”‚
   â–¼
2. ai_core/services.py::generate_text()
   â”‚
   â”œâ”€â–º Check AiMemory (prompt_hash lookup)
   â”‚   â””â”€â–º FOUND! (cache hit)
   â”‚       â”œâ”€â–º prompt_hash: abc123def456...
   â”‚       â”œâ”€â–º generated_text: "Welcome to..."
   â”‚       â”œâ”€â–º is_verified_good: True
   â”‚       â””â”€â–º usage_count: 1 â†’ 2
   â”‚
   â”œâ”€â–º Skip AI API call (cost: $0!)
   â”‚
   â”œâ”€â–º Log to AiUsageLog
   â”‚   â””â”€â–º cache_hit: True
   â”‚   â””â”€â–º cost: $0.00
   â”‚   â””â”€â–º latency_ms: 5 (instant!)
   â”‚
   â””â”€â–º Return: ("Welcome to...", "openai")
       â”‚
       â””â”€â–º Total savings: $0.05 per cache hit!
```

**Result**: 
- First request: $0.05 (850ms)
- Second request: $0.00 (5ms)
- **Savings: 100% cost, 99% latency!**

---

## ğŸµ Request Flow (Audio Generation)

### Scenario 1: First TTS Request (Cache Miss)

```
1. User requests audio: "Welcome to lesson 5"
   â”‚
   â–¼
2. ai_core/services.py::generate_audio()
   â”‚
   â”œâ”€â–º Compute text_hash
   â”‚   â””â”€â–º hash("Welcome to lesson 5" + "ja" + "Lily")
   â”‚       â””â”€â–º text_hash: xyz789abc123...
   â”‚
   â”œâ”€â–º Check AiMemory (audio cache)
   â”‚   â””â”€â–º NOT FOUND (cache miss)
   â”‚
   â”œâ”€â–º Select TTS Provider
   â”‚   â”œâ”€â–º Auto mode: Check for API keys
   â”‚   â”‚   â””â”€â–º ElevenLabs key exists â†’ Use ElevenLabs
   â”‚   â”‚
   â”‚   â””â”€â–º Manual mode: From UserCategoryConfig
   â”‚
   â”œâ”€â–º Call TTS Provider
   â”‚   â””â”€â–º ElevenLabs API
   â”‚       â””â”€â–º Response: MP3 audio bytes (2.3MB)
   â”‚       â””â”€â–º Cost: $0.003, Latency: 1500ms
   â”‚
   â”œâ”€â–º Save to AiMemory
   â”‚   â””â”€â–º prompt_hash: xyz789abc123...
   â”‚   â””â”€â–º request_type: tts_audio
   â”‚   â””â”€â–º generated_audio_file: xyz789abc.mp3
   â”‚   â””â”€â–º audio_metadata: {language: ja, voice: Lily}
   â”‚   â””â”€â–º provider: elevenlabs
   â”‚
   â”œâ”€â–º Log to AiUsageLog
   â”‚   â””â”€â–º cache_hit: False
   â”‚   â””â”€â–º cost: $0.003
   â”‚
   â””â”€â–º Return: (audio_bytes, "elevenlabs")
```

### Scenario 2: Second TTS Request (Cache Hit!)

```
1. User requests SAME audio
   â”‚
   â–¼
2. ai_core/services.py::generate_audio()
   â”‚
   â”œâ”€â–º Compute text_hash: xyz789abc123...
   â”‚
   â”œâ”€â–º Check AiMemory (audio cache)
   â”‚   â””â”€â–º FOUND! (cache hit)
   â”‚       â”œâ”€â–º generated_audio_file: xyz789abc.mp3
   â”‚       â”œâ”€â–º Read file from disk
   â”‚       â””â”€â–º usage_count: 1 â†’ 2
   â”‚
   â”œâ”€â–º Skip TTS API call (cost: $0!)
   â”‚
   â”œâ”€â–º Log to AiUsageLog
   â”‚   â””â”€â–º cache_hit: True
   â”‚   â””â”€â–º cost: $0.00
   â”‚   â””â”€â–º latency_ms: 3 (instant!)
   â”‚
   â””â”€â–º Return: (audio_bytes, "elevenlabs")
```

**Result**:
- First request: $0.003 (1500ms)
- Second request: $0.00 (3ms)
- **Savings: 100% cost, 99.8% latency!**

---

## ğŸ“Š Cost Tracking Flow

```
Every AI Request
    â”‚
    â–¼
1. generate_text() or generate_audio()
    â”‚
    â”œâ”€â–º Before API call: Check cache
    â”‚   â””â”€â–º Cache hit? Log and return
    â”‚
    â”œâ”€â–º API call: Track start time
    â”‚   â””â”€â–º Call provider (OpenAI, Gemini, etc.)
    â”‚       â””â”€â–º Get response + tokens used
    â”‚
    â”œâ”€â–º Calculate cost
    â”‚   â””â”€â–º tokens * cost_per_million / 1000000
    â”‚       â””â”€â–º Example: 1234 * $0.15 / 1M = $0.00019
    â”‚
    â”œâ”€â–º Save to AiMemory
    â”‚   â””â”€â–º Cache for future reuse
    â”‚
    â””â”€â–º Log to AiUsageLog
        â””â”€â–º Fields:
            â”œâ”€â–º request_type: podcast_script
            â”œâ”€â–º endpoint: dailycast.services.create_podcast
            â”œâ”€â–º user: alex@example.com
            â”œâ”€â–º provider: openai
            â”œâ”€â–º model: gpt-4o-mini
            â”œâ”€â–º tokens_used: 1234
            â”œâ”€â–º cost_estimate: 0.00019
            â”œâ”€â–º latency_ms: 850
            â”œâ”€â–º cache_hit: False
            â”œâ”€â–º success: True
            â””â”€â–º timestamp: 2025-12-10 15:30:45
```

---

## ğŸ“ Training Data Collection Flow

```
1. Content Generated (via AI Core)
   â”‚
   â–¼
2. Saved to AiMemory
   â”‚
   â”œâ”€â–º generated_text: "Welcome to lesson..."
   â”œâ”€â–º is_verified_good: False (default)
   â”œâ”€â–º use_for_training: False (default)
   â””â”€â–º user_rating: null
   â”‚
   â–¼
3. Admin Reviews in Django Admin
   â”‚
   â”œâ”€â–º Opens: /admin/ai_core/aimemory/
   â”‚
   â”œâ”€â–º Filters by:
   â”‚   â””â”€â–º request_type=podcast_script
   â”‚   â””â”€â–º usage_count > 10 (popular content)
   â”‚
   â”œâ”€â–º Reads generated content
   â”‚
   â””â”€â–º If GOOD:
       â””â”€â–º Action: "âœ“ Mark as Verified (Training)"
           â”œâ”€â–º Sets: is_verified_good = True
           â”œâ”€â–º Sets: use_for_training = True
           â””â”€â–º Creates: AiTrainingData entry
   â”‚
   â–¼
4. After 1,000+ Verified Examples
   â”‚
   â”œâ”€â–º Export: python manage.py export_training_data
   â”‚   â””â”€â–º Output: training_data.jsonl
   â”‚       â””â”€â–º Format: [
   â”‚               {"prompt": "...", "completion": "...", "tags": [...]},
   â”‚               ...
   â”‚           ]
   â”‚
   â”œâ”€â–º Fine-Tune Model
   â”‚   â””â”€â–º OpenAI: openai api fine_tunes.create \
   â”‚       --training_file training_data.jsonl \
   â”‚       --model gpt-4o-mini
   â”‚   â””â”€â–º Cost: ~$50-100 one-time
   â”‚   â””â”€â–º Result: ft:gpt-4o-mini:zporta:abc123
   â”‚
   â”œâ”€â–º Add to AiProviderConfig
   â”‚   â””â”€â–º provider: local_small_model
   â”‚   â””â”€â–º model_name: zporta_v1
   â”‚   â””â”€â–º tier: cheap
   â”‚   â””â”€â–º is_default: True
   â”‚
   â””â”€â–º Future Requests
       â””â”€â–º Auto mode now uses zporta_v1 (near-zero cost!)
       â””â”€â–º Falls back to external if quality drops
```

---

## ğŸ”€ Auto vs Manual Selection

### Auto Mode (Recommended)

```
User Request
    â”‚
    â–¼
generate_text(selection_mode='auto')
    â”‚
    â”œâ”€â–º Determine Content Tier
    â”‚   â”œâ”€â–º Simple quiz â†’ cheap tier
    â”‚   â”œâ”€â–º Podcast script â†’ normal tier
    â”‚   â””â”€â–º Complex analysis â†’ premium tier
    â”‚
    â”œâ”€â–º Query AiProviderConfig
    â”‚   â””â”€â–º SELECT * FROM ai_provider_config
    â”‚       WHERE tier = 'normal'
    â”‚       AND is_active = True
    â”‚       ORDER BY cost_per_million_tokens ASC, quality_score DESC
    â”‚       LIMIT 1
    â”‚
    â””â”€â–º Result: openai/gpt-4o-mini ($0.15/1M, quality: 0.85)
```

### Manual Mode (Power Users)

```
User/Admin selects in dropdown:
    â”œâ”€â–º Provider: OpenAI
    â””â”€â–º Model: gpt-4o
    â”‚
    â–¼
generate_text(
    provider='openai',
    model='gpt-4o',
    selection_mode='manual'
)
    â”‚
    â””â”€â–º Uses exactly what user specified
        â””â”€â–º Ignores auto-selection logic
        â””â”€â–º Still logs cost and caches result
```

---

## ğŸ“ˆ Cost Savings Over Time

```
Month 1: No AI Core
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
10,000 requests Ã— $0.05 avg = $500
Cache hit rate: 0%
Savings: $0

Month 2: AI Core Enabled (Caching Only)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
10,000 requests:
  - 8,000 cache hits (80%) â†’ $0
  - 2,000 API calls â†’ $100
Cache hit rate: 80%
Savings: $400 (80%)

Month 4: + Fine-Tuned Model (zporta_v1)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
10,000 requests:
  - 8,000 cache hits (80%) â†’ $0
  - 2,000 API calls:
      - 1,500 use zporta_v1 (75%) â†’ $15
      - 500 use external (25%) â†’ $25
Cache hit rate: 80%
Local model usage: 75% of non-cached
Savings: $460 (92%)

Year 1: Mature System
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
10,000 requests/month:
  - 9,000 cache hits (90%) â†’ $0
  - 1,000 API calls:
      - 900 use zporta_v1 â†’ $9
      - 100 use external â†’ $5
Total: $14/month (was $500/month)
Savings: $486/month (97%)
Annual savings: $5,832
```

---

## ğŸ¯ Key Decision Points

### When to Use Cache?
- âœ… **Always check** (default behavior)
- âŒ **Skip** (`force_refresh=True`) only when:
  - User explicitly requests "regenerate"
  - Content is time-sensitive (news, updates)
  - Testing new prompts

### When to Use Auto Mode?
- âœ… **Default** for all routine content
- âœ… When cost efficiency matters
- âœ… For most users (they don't care about model)

### When to Use Manual Mode?
- âœ… Power users who know models
- âœ… A/B testing different providers
- âœ… Debugging quality issues
- âœ… Special requirements (e.g., "must use Claude")

### When to Mark for Training?
- âœ… Content rated 4.5+ stars by users
- âœ… Admin manually verified as high quality
- âœ… Representative of "Zporta style"
- âœ… No personal/sensitive data

### When to Fine-Tune?
- âœ… After 1,000+ verified examples
- âœ… Every 3-6 months (incremental)
- âœ… When cost savings justify $50-100 training cost

---

## ğŸš€ Summary

**Data Flow**: Request â†’ Cache Check â†’ AI Provider â†’ Save Cache â†’ Log Usage

**Cost Flow**: Track every request â†’ Monitor dashboard â†’ Identify savings

**Training Flow**: Generate â†’ Verify â†’ Collect â†’ Fine-Tune â†’ Deploy

**Integration**: Coexists with old code â†’ Gradually replace â†’ No breaking changes

**Result**: 80%+ cost savings + Training data for free + Clean unified API

ğŸ‰ **This is how modern AI systems should work!**
