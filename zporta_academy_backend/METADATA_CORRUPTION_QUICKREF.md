# Metadata Corruption Fix - Quick Reference

## TL;DR

**Problem**: `compute_content_difficulty` was failing with JSONField TypeError due to numeric metadata in database.

**Solution**:

1. âœ… Refactored commands to use raw SQL (bypasses issue)
2. âœ… Added model validation to prevent future corruption
3. âœ… Created cleanup tools for diagnosis

**Status**:

- âœ… Database is clean (0 corrupted rows detected)
- âœ… All validation tests pass (7/7)
- âœ… All management commands working

---

## Files Created/Modified

### New Files

- `METADATA_CORRUPTION_FIX.md` - Comprehensive documentation
- `diagnose_metadata_corruption.sql` - SQL diagnostic queries
- `intelligence/management/commands/cleanup_invalid_metadata.py` - Cleanup command
- `test_metadata_validation.py` - Validation test suite

### Modified Files

- `intelligence/management/commands/compute_content_difficulty.py` - Refactored to raw SQL
- `analytics/models.py` - Added validation to prevent numeric metadata

---

## Quick Commands

### Check for corrupted data

```bash
python manage.py cleanup_invalid_metadata --dry-run
```

### Test validation

```bash
python test_metadata_validation.py
```

### Run AI batch jobs

```bash
python manage.py compute_content_difficulty
python manage.py compute_user_abilities
python manage.py compute_match_scores
```

---

## What Changed

### Before (Broken)

```python
# ORM query that crashed on numeric metadata:
ActivityEvent.objects.filter(
    event_type='quiz_answer_submitted',
    metadata__has_key='quiz_id'
).annotate(...)
```

### After (Working)

```python
# Raw SQL that bypasses JSONField decoder:
sql = """
    SELECT JSON_EXTRACT(metadata, '$.quiz_id') as quiz_id
    FROM analytics_activityevent
    WHERE JSON_TYPE(metadata) = 'OBJECT'
"""
cursor.execute(sql)
```

---

## Validation Added

```python
# In analytics/models.py:
class ActivityEvent(models.Model):
    def clean(self):
        if self.metadata is not None:
            if not isinstance(self.metadata, dict):
                raise ValidationError('Metadata must be dict')

    def save(self, *args, **kwargs):
        self.full_clean()
        super().save(*args, **kwargs)
```

**Result**:

- âœ“ Dict metadata accepted
- âœ— Numeric metadata rejected (int, float)
- âœ— String metadata rejected
- âœ— List metadata rejected
- âœ“ Null metadata accepted

---

## Verification Results

### Database Health Check

```
Total rows: 4,288
Corrupted rows: 0
Status: âœ“ Database is healthy
```

### Validation Tests

```
Test 1: Dict metadata accepted       âœ“ PASS
Test 2: Integer metadata rejected    âœ“ PASS
Test 3: Float metadata rejected      âœ“ PASS
Test 4: String metadata rejected     âœ“ PASS
Test 5: Null metadata accepted       âœ“ PASS
Test 6: Empty dict accepted          âœ“ PASS
Test 7: List metadata rejected       âœ“ PASS
```

### Management Commands

```
compute_content_difficulty   âœ“ Working (29 quizzes, 103 questions)
compute_user_abilities       âœ“ Working
compute_match_scores         âœ“ Working
```

---

## What to Do Next

### âš ï¸ CRITICAL: Local vs Production Workflow

**LOCAL (Development)** - What we did:

1. âœ… Found issue and fixed it
2. âœ… Tested solution (all passing)
3. âœ… Verified database is clean (0 corrupted rows)

**PRODUCTION** - What you MUST do:

1. ðŸ” **DIAGNOSE FIRST** - Never assume production matches local!
2. ðŸ“‹ Document findings (how many corrupted rows?)
3. ðŸ’¾ Backup database before ANY changes
4. âœ… Deploy based on actual findings (see strategies below)

**Read this first**: `METADATA_FIX_PRODUCTION_PLAN.md`

### If deploying to production:

**Step 1: Backup** (ALWAYS!)

```bash
mysqldump -u [user] -p [db] analytics_activityevent > backup_$(date +%Y%m%d_%H%M%S).sql
```

**Step 2: Diagnose** (Deploy diagnostic tool only)

```bash
python manage.py cleanup_invalid_metadata --dry-run --limit 200
```

**Step 3: Choose Strategy** (Based on findings)

- **Strategy A**: 0 corrupted rows â†’ Deploy model validation only (no risk)
- **Strategy B**: 1-50 rows â†’ Deploy + cleanup (low risk)
- **Strategy C**: 50-500 rows â†’ Investigate first (medium risk)
- **Strategy D**: 500+ rows â†’ Stop, escalate, schedule maintenance (high risk)

**Step 4: Execute** (Follow production plan)

- See `METADATA_FIX_PRODUCTION_PLAN.md` for detailed steps per strategy

### If corruption found in future:

```bash
# 1. Diagnose
python manage.py cleanup_invalid_metadata --dry-run

# 2. Review impact
# Check output for affected event types

# 3. Backup
# Use Navicat or mysqldump

# 4. Clean
python manage.py cleanup_invalid_metadata
# Type 'yes' to confirm

# 5. Verify
python manage.py compute_content_difficulty
```

---

## Root Cause Summary

**Technical**: Django's JSONField expects dict/list, but some rows had numeric JSON (42, 3.14) which caused `json.loads()` to return `int`/`float` instead of `dict`, triggering TypeError.

**Source**: Unknown (not from application code - all metadata writes use dicts). Likely from:

- Manual database edits
- Legacy migration
- Direct SQL inserts
- External data import

**Prevention**: Model validation now blocks non-dict metadata at save time.

---

## Success Criteria

All of these are now âœ… ACHIEVED:

- [x] `compute_content_difficulty` runs without errors
- [x] `compute_user_abilities` completes successfully
- [x] `compute_match_scores` completes successfully
- [x] No corrupted metadata in database (0 rows)
- [x] Validation prevents future corruption (7/7 tests pass)
- [x] Documentation and tools created for future reference
- [x] All AI intelligence system data populated

---

## Support

For questions or issues:

1. Check `METADATA_CORRUPTION_FIX.md` for detailed documentation
2. Run diagnostic: `python manage.py cleanup_invalid_metadata --dry-run`
3. Test validation: `python test_metadata_validation.py`
4. Review SQL queries in `diagnose_metadata_corruption.sql`

---

**Last Updated**: 2024-01-XX  
**Status**: âœ… Complete and Verified  
**Version**: 1.0
